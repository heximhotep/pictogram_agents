{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dm_control import suite\n",
    "from dm_control import mujoco\n",
    "from IPython.display import clear_output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n",
      "joint_angles [0] (7,)\n",
      "(7,)\n",
      "upright [7] ()\n",
      "target [8] (3,)\n",
      "(3,)\n",
      "velocity [11] (13,)\n",
      "(13,)\n",
      "(24,)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "env = suite.load(domain_name=\"fish\", task_name=\"swim\")\n",
    "action_spec = env.action_spec()\n",
    "observation_spec = env.observation_spec()\n",
    "observation_shape = np.array([0])\n",
    "time_step = env.reset()\n",
    "print(type(observation_spec))\n",
    "for (name, row) in observation_spec.items():\n",
    "    print (name, observation_shape, row.shape)\n",
    "    if(row.shape == ()):\n",
    "        observation_shape[0] += 1\n",
    "        continue\n",
    "    print(row.shape)\n",
    "    observation_shape[0] += row.shape[0]\n",
    "observation_shape = (observation_shape[0],)\n",
    "print(observation_shape)\n",
    "print(action_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation2state(obs):\n",
    "    result = np.array([])\n",
    "    for(_, data) in obs.items():\n",
    "        result = np.append(result, data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorforce.agents import PPOAgent\n",
    "from tensorforce.agents import RandomAgent\n",
    "agent = PPOAgent(\n",
    "    states=dict(type='float', min_value=action_spec.minimum[0], max_value=action_spec.maximum[0], shape=observation_shape),\n",
    "    actions=dict(type='float', min_value=action_spec.minimum[0], max_value=action_spec.maximum[0], shape=action_spec.shape),\n",
    "    network=[\n",
    "        dict(type='dense', size=256, activation='tanh'),\n",
    "        dict(type='dense', size=256, activation='tanh'),\n",
    "        dict(type='dense', size=256, activation='tanh')\n",
    "    ],\n",
    "    step_optimizer={\n",
    "        \"type\": \"adam\",\n",
    "        \"learning_rate\": 1e-3\n",
    "    },\n",
    "    entropy_regularization=0.01,\n",
    "    batching_capacity=1024,\n",
    "    subsampling_fraction=0.1,\n",
    "    optimization_steps=50,\n",
    "    discount=0.99,\n",
    "    likelihood_ratio_clipping=0.2,\n",
    "    baseline_mode=\"states\",\n",
    "    baseline={\n",
    "        \"type\":\"mlp\",\n",
    "        \"sizes\": [32, 32]\n",
    "    },\n",
    "    baseline_optimizer={\n",
    "        \"type\":\"multi_step\",\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"learning_rate\": 1e-3\n",
    "        },\n",
    "        \"num_steps\": 5\n",
    "    },\n",
    "    update_mode={\n",
    "        \"unit\": \"episodes\",\n",
    "        \"batch_size\": 10,\n",
    "        \"frequency\": 10\n",
    "    },\n",
    "    memory={\n",
    "        \"type\": \"latest\",\n",
    "        \"include_next_states\": False,\n",
    "        \"capacity\": 5000\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for episode 10204 : 33.741492156359314\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "\n",
    "img = None\n",
    "NUM_EPISODES = 25000\n",
    "\n",
    "for i in range(NUM_EPISODES):\n",
    "    time_step = env.reset()\n",
    "    j = 0\n",
    "    tot = 0\n",
    "    while not time_step.last():\n",
    "        state = observation2state(time_step.observation)\n",
    "        action = agent.act(state)\n",
    "        time_step = env.step(action)\n",
    "        tot += time_step.reward\n",
    "        agent.observe(reward=time_step.reward, terminal=time_step.last())\n",
    "        if(j % 50 == 0 and i % 25 == 1):\n",
    "            \n",
    "            clear_output()\n",
    "            img = plt.imshow(np.array(env.physics.render(480, 640)).reshape(480, 640, 3))\n",
    "            plt.pause(0.5)\n",
    "            \n",
    "        j += 1\n",
    "    if (j > 0):\n",
    "        #tot /= j\n",
    "        clear_output()\n",
    "        print(\"for episode\", i, \":\", tot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
